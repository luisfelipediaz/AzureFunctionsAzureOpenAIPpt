<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure Functions with Azure OpenAI</title>
    <link rel="stylesheet" href="/node_modules/reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="/node_modules/reveal.js/dist/theme/black.css" />
    <link rel="stylesheet" href="/node_modules/reveal.js/plugin/highlight/monokai.css">
    <style>
        .intro-section h1 {
            font-size: 2.5em;
        }

        .intro-section p {
            font-size: 1.2em;
        }

        .intro-section .company-name {
            font-size: 1em;
            font-style: italic;
            color: #888;
        }
    </style>
</head>

<body>
    <div class="reveal">
        <div class="slides">
            <!-- Slide 1: Introducción -->
            <section class="intro-section" data-background-color="#020b14">
                <img src="https://bitakora.co/wp-content/uploads/2024/07/Logo-Bitakora-W.png" alt="reveal.js logo"
                    style="height: 180px; margin: 0 auto 4rem auto; background: transparent;" class="demo-logo">

                <h3>Desarrollando con Azure Functions y Azure OpenAI</h3>
                <p><small>Teoría y práctica para la creación de aplicaciones modernas</small></p>
                <p><small><strong>Nombre:</strong> Luis Felipe Díaz Valbuena</small></p>
            </section>

            <!-- Slide 2: Agenda -->
            <section data-background-color="#020b14">
                <h3>Agenda</h3>
                <ul>
                    <li>Azure Functions: Introducción</li>
                    <li>Azure OpenAI: ¿Qué es?</li>
                    <li>Azure OpenAI: Beneficios</li>
                    <li>El problema / Diagrama Arquitectónico</li>
                    <li>Demostración práctica</li>
                    <li>Mejores prácticas</li>
                    <li>Resultados y futuro</li>
                    <li>Conclusiones</li>
                    <li>Preguntas sin respuestas</li>
                </ul>
            </section>

            <!-- Slide 3: Azure Functions -->
            <section data-background-color="#020b14">
                <h3>Azure Functions: Introducción</h3>
                <small>
                    <p>Ejecución de código bajo demanda en la nube, sin necesidad de administrar infraestructura.</p>
                    <ul>
                        <li>Escalabilidad automática</li>
                        <li>Pago solo por el tiempo de ejecución</li>
                        <li>Simplificación de la infraestructura, sin servidores que gestionar</li>
                    </ul>
                </small>
            </section>

            <!-- Slide 4: Tipos de Funciones -->
            <section data-background-color="#020b14">
                <h3>Azure Functions: Tipos de funciones</h3>
                <small>
                    <p><strong>Tipos de funciones que se pueden ejecutar:</strong></p>
                    <ul>
                        <li><strong>HTTP Trigger:</strong> Funciones que responden a solicitudes HTTP, ideales para
                            crear
                            APIs o endpoints.</li>
                        <li><strong>Event Grid Trigger:</strong> Funciones que se activan por eventos de Azure Event
                            Grid, como la carga de archivos a Blob Storage.</li>
                        <li><strong>Queue Trigger:</strong> Funciones que se activan por mensajes en colas de Azure
                            Storage, útil para procesar tareas en segundo plano.</li>
                        <li><strong>Timer Trigger:</strong> Funciones que se ejecutan en intervalos específicos, como un
                            cron job.</li>
                        <li><strong>Cosmos DB Trigger:</strong> Funciones que reaccionan a cambios en una base de datos
                            Cosmos DB.</li>
                        <li><strong>Webhook Trigger:</strong> Funciones que responden a eventos externos a través de un
                            webhook.</li>
                    </ul>
                    <p><strong>Ejemplos:</strong> Procesamiento de datos, integración con APIs, webhooks, tareas
                        programadas.</p>
                </small>
            </section>

            <!-- Slide 5: Azure OpenAI: ¿Qué es? -->
            <section data-background-color="#020b14">
                <h3>Azure OpenAI: ¿Qué es?</h3>
                <ul>
                    <li>Servicio que integra los modelos avanzados de OpenAI en la nube de Azure.</li>
                    <li>Modelos soportados:
                        <ul>
                            <li><strong>GPT</strong>: Generación de texto y chatbots.</li>
                            <li><strong>Codex</strong>: Comprensión de código.</li>
                            <li><strong>DALL-E</strong>: Generación de imágenes.</li>
                        </ul>
                    </li>
                </ul>
            </section>

            <!-- Slide 6: Azure OpenAI: Beneficios -->
            <section data-background-color="#020b14">
                <h3>Azure OpenAI: Beneficios</h3>
                <ul>
                    <li>Seguridad y cumplimiento empresarial.</li>
                    <li>Escalabilidad y fiabilidad en la infraestructura de Azure.</li>
                    <li>Integración sencilla con otros servicios de Azure.</li>
                </ul>
            </section>

            <!-- Slide 7: El problema -->
            <section data-background-color="#020b14">
                <h3>El problema</h3>
                <p><small>En miBitákora, los empleados pueden enviar una foto de su incapacidad para que se procese
                        automáticamente. Usamos Azure Functions junto con Tesseract.js para extraer el texto de la
                        imagen y Azure OpenAI para obtener los datos relevantes de la incapacidad.</small></p>
                <p><small>El flujo de procesamiento incluye varias validaciones, como la autenticación del token, la
                        validación de la imagen y la extracción de los datos. El siguiente diagrama describe este
                        proceso.</small></p>
            </section>

            <!-- Slide 8: Diagrama de Flujo -->
            <section data-background-color="#020b14">
                <h3>Diagrama de Flujo</h3>
                <img src="./mermaid-diagram-2024-12-11-142038.svg" alt="Diagrama Arquitectónico"
                    style="height: 400px; margin: 0 auto 4rem auto; background: transparent;">
            </section>

            <!-- Slide 9: Demostración Práctica -->
            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Demostración Práctica</h3>
                <p data-id="demostracion-contenido"><strong>Objetivo:</strong> Crear una función que reciba una imagen y
                    devuelva una incapacidad
                    por Azure OpenAI.</p>
                <ol>
                    <li>Configurar el entorno</li>
                    <li>Escribir código en Azure Functions</li>
                    <li>Integrar con Azure OpenAI</li>
                    <li>Probar y ejecutar</li>
                </ol>
            </section>

            <!-- Slide 10: Configurar el entorno -->
            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Configurar el entorno</h3>
                <div data-id="demostracion-contenido">
                    <span class="fragment"><strong>Paso 1:</strong> Crear una cuenta de Azure y un recurso de Azure
                        Functions.
                    </span>
                    <br />
                    <span class="fragment"><strong>Paso 2:</strong> Instalar las herramientas de Azure
                        Functions en tu máquina local.
                    </span>
                    <br />
                    <span class="fragment"><strong>Paso 3:</strong> Desplegar el modelo de gpt-4o-mini desde Azure AI
                        Foundry.
                    </span>
                    <br />
                    <span class="fragment"><strong>Paso 4:</strong> Crear un proyecto de Azure Functions en Visual
                        Studio
                        Code con este comando:
                        <pre>
                        <code class="hljs zsh" data-trim data-line-numbers>
                            <script type="text/template">
                            func init --worker-runtime node --language typescript
                            func new --template "Http Trigger" --name {{NOMBRE_FUNCION}}
                        </script>
                        </code>
                    </pre>
                    </span>
                </div>
            </section>

            <!-- Slide 11: Debería verse algo así -->
            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Debería verse algo así:</h3>
                <div data-id="demostracion-contenido">
                    <img src="./scaffolding.png" alt="Estructura de carpetas de Azure Functions"
                        style="height: 400px; margin: 0 auto 4rem auto; background: transparent;">
                </div>
            </section>

            <!-- Slide 12: Pillemos el código -->
            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Pillemos el código:</h3>
                <pre data-id="demostracion-codigo">
                    <code class="hljs typescript" data-trim data-line-numbers="7-11">
                        <script type="text/template">
                        import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

                        export async function IncapacidadesIA(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
                            ....
                        };

                        app.http('IncapacidadesIA', {
                            methods: ['GET', 'POST'],
                            authLevel: 'anonymous',
                            handler: IncapacidadesIA
                        });
                        </script>
                    </code>
                </pre>
            </section>


            <!-- Slide 13: Pillemos el código -->
            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Pillemos el código:</h3>
                <pre data-id="demostracion-codigo">
                    <code class="hljs typescript" data-trim data-line-numbers="4-8">
                        <script type="text/template">
                        import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

                        export async function IncapacidadesIA(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
                            context.log(`Http function processed request for url "${request.url}"`);

                            const name = request.query.get('name') || await request.text() || 'world';

                            return { body: `Hello, ${name}!` };
                        };

                        app.http('IncapacidadesIA', {
                            methods: ['GET', 'POST'],
                            authLevel: 'anonymous',
                            handler: IncapacidadesIA
                        });
                    </script>
                    </code>
                </pre>
            </section>

            <!-- Slide 14: Nos toca instalar algunos paquetes -->
            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Nos toca instalar algunos paquetes:</h3>
                <pre data-id="demostracion-codigo">
                    <code class="hljs bash" data-trim data-line-numbers>
                        <script type="text/template">
                        npm install tesseract.js // OCR
                        npm install openai // Azure OpenAI
                        npm install formidable // Procesamiento de archivos
                        npm install jose // Autenticación JWT
                    </script>
                    </code>
                </pre>
            </section>


            <!-- Slide 15: GIF -->
            <section data-background="http://i.giphy.com/90F8aUepslB84.gif">
                <h2>... y ya?</h2>
                <div class="fragment">
                    <p>Ps no, hay que obtener las claves de GPT, configurar los limites de tokens y
                        programar</p>
                    <img src="https://www.topito.com/wp-content/uploads/2013/01/code-21.gif" alt="GIF" />
                </div>
                <p class="fragment">Supongamos que ya lo hicimos ----></p>
            </section>

            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Pillemos el código:</h3>
                <pre data-id="demostracion-codigo">
                    <code class="hljs typescript" data-trim data-line-numbers="|7-12|16-18|20-29|31-36|38">
                        <script type="text/template">
                            import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
                            import { obtenerIncapacidadDesdeImagen } from "../AI";
                            import { autenticarToken } from "../Auth";
                            import { obtenerTextoDeLaImagen } from "../OCR";
                            import { obtenerImagenesDelRequest } from "../Request";
                            
                            const INVALID_FILE_TYPE = "Invalid file type";
                            const INVALID_IMAGE = "Invalid image";
                            const ONLY_ONE_IMAGE = "Only one image file is allowed";
                            const NO_IMAGE_FILE = "No image file provided";
                            const UNAUTHORIZED = "Unauthorized";
                            const LOW_CONFIDENCE = "Low confidence";
                            
                            export async function IncapacidadesIA(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
                                try {
                                    const isAuthenticated = await autenticarToken(request.headers.get('Authorization'));
                                    if (!isAuthenticated)
                                        return { status: 401, body: UNAUTHORIZED };
                            
                                    const { image } = await obtenerImagenesDelRequest(request);
                                    if (!image || image.length === 0)
                                        return { status: 400, body: NO_IMAGE_FILE };
                                    if (image.length > 1)
                                        return { status: 400, body: ONLY_ONE_IMAGE };
                            
                                    const [incapacidadFile] = image;
                            
                                    if (!incapacidadFile.mimetype.startsWith('image/'))
                                        return { status: 400, body: INVALID_FILE_TYPE };
                            
                                    const OCRResult = await obtenerTextoDeLaImagen(incapacidadFile.filepath);
                            
                                    if (OCRResult.confidence < 60)
                                        return { status: 422, body: `${LOW_CONFIDENCE}: ${OCRResult.confidence}` };
                                    if (!OCRResult.valid)
                                        return { status: 400, body: INVALID_IMAGE };
                            
                                    const gptResult = await obtenerIncapacidadDesdeImagen(incapacidadFile);
                            
                                    return { body: JSON.stringify(gptResult), headers: { 'Content-Type': 'application/json' } };
                                } catch (error) {
                                    context.error('Error:', error);
                                    return { status: 500, body: error.message };
                                }
                            }
                            
                            app.http('IncapacidadesIA', {
                                methods: ['POST'],
                                authLevel: 'anonymous',
                                handler: IncapacidadesIA
                            });
                    </script>
                    </code>
                </pre>
            </section>

            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">La IA:</h3>
                <pre data-id="demostracion-codigo-2">
                    <code class="hljs typescript" data-trim data-line-numbers="|5-10|13-14|16-33|35|38-47|">
                        <script type="text/template">
                            import { File } from 'formidable';
                            import { promises as fs } from 'fs';
                            import { AzureOpenAI } from "openai";

                            const openai = new AzureOpenAI({
                                deployment: 'gpt-4o-mini',
                                apiVersion: '2024-10-21',
                                endpoint: process.env['AZUREOPENAI_ENDPOINT'],
                                apiKey: process.env['AZUREOPENAI_APIKEY']
                            });

                            export async function obtenerIncapacidadDesdeImagen(image: File) {
                                const fileBuffer = await fs.readFile(image.filepath);
                                const imageBase64 = fileBuffer.toString('base64');
                                try {
                                    const completion = await openai.chat.completions.create({
                                        model: 'gpt-4o-mini',
                                        messages: [
                                            { role: 'system', content: `Sorry but I can't show you the fucking prompt because this repo is public.`, },
                                            { 
                                                role: 'user',
                                                content: [
                                                    {
                                                        type: 'image_url',
                                                        image_url: {
                                                            url: `data:${image.mimetype};base64,${imageBase64}`
                                                        }
                                                    }
                                                ]
                                            },
                                        ],
                                        max_tokens: 300
                                    });

                                    const gptContent = completion.choices[0].message.content.trim();

                                    // Try to safely parse the JSON content
                                    const jsonStart = gptContent.indexOf('{');
                                    const jsonEnd = gptContent.lastIndexOf('}');

                                    if (jsonStart !== -1 && jsonEnd !== -1) {
                                        const jsonString = gptContent.substring(jsonStart, jsonEnd + 1);
                                        const parsedJson = JSON.parse(jsonString);
                                        return parsedJson;
                                    } else {
                                        throw new Error('JSON not found in GPT response');
                                    }
                                } catch (error) {
                                    console.error('Error calling GPT API:', error);
                                    throw error;
                                }
                            }
                    </script>
                    </code>
                </pre>
            </section>

            <section data-background-color="#020b14" data-auto-animate>
                <h3 data-id="demostracion-title">Se puede mejorar:</h3>
                <pre data-id="demostracion-codigo-2">
                    <code class="hljs typescript" data-trim data-line-numbers="|19-36|44">
                        <script type="text/template">
                            import { File } from 'formidable';
                            import { promises as fs } from 'fs';
                            import { AzureOpenAI } from "openai";

                            const openai = new AzureOpenAI({
                                ...
                            });

                            // Antes - Despues = Diferencia
                            // Total tokens: 37065 - 37119 = 54
                            // Token de respuesta($): 88 - 62 = 26

                            export async function obtenerIncapacidadDesdeImagen(image: File) {
                                const fileBuffer = await fs.readFile(image.filepath);
                                const imageBase64 = fileBuffer.toString('base64');
                                try {
                                    const completion = await openai.chat.completions.create({
                                        model: 'gpt-4o-mini',
                                        response_format: {
                                            type: 'json_schema',
                                            json_schema: {
                                                name: 'incapacidades_schema',
                                                schema: {
                                                    type: 'object',
                                                    properties: {
                                                        consecutivo: { type: 'number' },
                                                        fecha: { type: 'string', format: 'date-time' },
                                                        diagnostico: { type: 'string' },
                                                        cantidadDias: { type: 'number' },
                                                        fechaInicio: { type: 'string', format: 'date' },
                                                        causa: { type: 'string' },
                                                        identificacion: { type: 'string' },
                                                    }
                                                },
                                            }
                                        },
                                        messages: [
                                           ....
                                        ]
                                    });

                                    const gptContent = completion.choices[0].message.content.trim();

                                    return JSON.parse(gptContent);
                                } catch (error) {
                                    console.error('Error calling GPT API:', error);
                                    throw error;
                                }
                            }
                    </script>
                    </code>
                </pre>
            </section>

            <!-- Slide: Mejores Práctivas -->
            <section data-background-color="#020b14">
                <h3>Mejores Prácticas</h3>
                <ul>
                    <li>Gestión de secretos con Azure Key Vault</li>
                    <li>Control de costos</li>
                    <li>Monitoreo con Application Insights</li>
                </ul>
            </section>


            <!-- Slide 16: Resultados y Futuro -->
            <section data-background-color="#020b14">
                <h3>Resultados y Futuro</h3>
                <p>Cómo las empresas pueden aprovechar esta integración</p>
                <p>Potenciales mejoras futuras en Azure OpenAI</p>
            </section>

            <!-- Slide 17: Conclusiones -->
            <section data-background-color="#020b14">
                <h3>Conclusiones</h3>
                <ul>
                    <li>Resumen de la sesión</li>
                    <li>Inspírate para explorar más integraciones</li>
                    <li>Comienza a construir con Azure</li>
                </ul>
            </section>

            <!-- Slide 18: Conclusiones -->
            <section data-background-color="#020b14">
                <h3>Preguntas sin Respuestas</h3>
                <p>Espacio para ampliar dudas del público.</p>
            </section>

            <!-- Slide 19: Gracias -->
            <section data-background-color="#020b14">
                <h3>¡Gracias!</h3>
            </section>
        </div>
    </div>
    <script type="module" src="./index.js"></script>

</body>

</html>